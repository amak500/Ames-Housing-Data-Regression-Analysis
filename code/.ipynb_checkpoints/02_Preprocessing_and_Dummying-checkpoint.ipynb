{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Dummying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to split our data into x and y training and test sets, so that we can use those sets in order to fit our models for the most accurate predictions. Additionally, we will dummy out columns containing categorical variables, so that we can see the effect each category has on our prediciton as a whole. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import csv\n",
    "import re\n",
    "import time\n",
    "np.random.seed(42)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This imports all of the libraries we need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_training_data_cleaned = pd.read_pickle(\"../datasets/training_data_cleaned.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reads in the pickle of the cleaned training data that we reated in 01_Cleaning_and_EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_training_data_cleaned.set_index('Id',inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sets the index of the cleaned training data equal to the Id column.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_training_data_cleaned.drop('PID', 1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This drops the PID column, as it is a categorical variable that does not contribute towards our model in any meaningful way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_training_data_cleaned_dummies = pd.get_dummies(ames_training_data_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dummies out the categorical variables into their own separate columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2051, 377)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ames_training_data_cleaned_dummies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of features has gone up from 81 to 377, as a result of the dummying. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ames_training_data_cleaned_dummies.drop('SalePrice', 1)\n",
    "y = ames_training_data_cleaned_dummies.SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sets the predictor variables to every variable that isn't the sale price, and the predicted variable to the sale price. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This splits the training data into a train set and a test set at a ratio of 0.75 to 0.25. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = VarianceThreshold(.05)\n",
    "X_train_thresh = threshold.fit_transform(X_train)\n",
    "X_test_thresh = threshold.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This removes all features with a variance lower than 0.05. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X.columns[threshold.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This preserves an ordered list of the columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train_thresh)\n",
    "X_test_sc = ss.transform(X_test_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This scales the data to an approximately Normal distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_pickle(\"../datasets/training_data_cleaned_X.pkl\")\n",
    "y.to_pickle(\"../datasets/training_data_cleaned_y.pkl\")\n",
    "np.save('../datasets/columns',columns)\n",
    "np.save('../datasets/X_train_sc',X_train_sc)\n",
    "np.save('../datasets/X_test_sc',X_test_sc)\n",
    "np.save('../datasets/y_train',y_train)\n",
    "np.save('../datasets/y_test',y_test)\n",
    "pickle.dump(ss, open('../datasets/ss.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This saves the data out to be reused later. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
